{
 "metadata": {
  "name": "Recent Earthquakes"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Group 3 Recent Earthquakes Data Cleaning and Visualization.\nInitial steps: import the following libraries and choose the url you want to pull the data from."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import urllib\nimport json\nimport pandas as pd\nurl=\"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.geojson\"",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": "/usr/local/lib/python2.7/dist-packages/pytz/__init__.py:29: UserWarning: Module dap was already imported from None, but /usr/lib/python2.7/dist-packages is being added to sys.path\n  from pkg_resources import resource_stream\n"
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Use the JSON library to parse the data into a form we can read."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "data=json.loads(urllib.urlopen(url).read())\nrecords=len(data[unicode(\"features\")])",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Define functions to extract the values from a single cell."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def getEpicData(dataset, path, number):\n    if type(path)!=list:\n        print \"2nd argument must be a list\"\n        return\n    if type(number)!=int:\n        print \"3rd argument must be a int\"\n    if type(dataset)==dict:\n        data=dataset[u'features'][number]\n    else:\n        data=dataset[number]\n    for nr in range(len(path)):\n        if type(path[nr])==str:\n            data=data[unicode(path[nr])]\n        else:\n            data=data[path[nr]]\n    if type(data)==unicode:\n        data=str(data)\n    return data\n\nkeyId=[\"id\"]\n\nkeyGeoLongtitude=[\"geometry\",\"coordinates\",0]\nkeyGeoLatitude  =[\"geometry\",\"coordinates\",1]\nkeyGeoDepth     =[\"geometry\",\"coordinates\",2]\nkeyGeoType      =[\"geometry\",\"type\"]\n\nkeyPropAlert  =[\"properties\",\"alert\"]\nkeyPropCdi    =[\"properties\",\"cdi\"]\nkeyPropCode   =[\"properties\",\"code\"]\nkeyPropDetail =[\"properties\",\"detail\"]\nkeyPropDmin   =[\"properties\",\"dmin\"]\nkeyPropFelt   =[\"properties\",\"felt\"]\nkeyPropGap    =[\"properties\",\"gap\"]\nkeyPropIds    =[\"properties\",\"ids\"]\nkeyPropMag    =[\"properties\",\"mag\"]\nkeyPropMagType=[\"properties\",\"magType\"]\nkeyPropMmi    =[\"properties\",\"mmi\"]\nkeyPropNet    =[\"properties\",\"net\"]\nkeyPropNst    =[\"properties\",\"nst\"]\nkeyPropPlace  =[\"properties\",\"place\"]\nkeyPropRms    =[\"properties\",\"rms\"]\nkeyPropSig    =[\"properties\",\"sig\"]\nkeyPropSources=[\"properties\",\"sources\"]\nkeyPropStatus =[\"properties\",\"status\"]\nkeyPropTime   =[\"properties\",\"time\"]\nkeyPropTitle  =[\"properties\",\"title\"]\nkeyPropTsunami=[\"properties\",\"tsunami\"]\nkeyPropType   =[\"properties\",\"type\"]\nkeyPropTypes  =[\"properties\",\"types\"]\nkeyPropTz     =[\"properties\",\"tz\"]\nkeyPropUpdated=[\"properties\",\"updated\"]\nkeyPropUrl    =[\"properties\",\"url\"]\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Get these values into individual lists."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def getEpicDataList(dataset, path, records):\n    datalist=[]\n    for nr in range(records):\n        info=getEpicData(dataset, path, nr)\n        datalist.append(info)\n    return datalist\n    \n# Extract data into lists\nlistId=getEpicDataList(data, keyId, records)\n\nlistGeoLongitude=getEpicDataList(data, keyGeoLongtitude, records)\nlistGeoLatitude=getEpicDataList(data, keyGeoLatitude, records)\nlistGeoDepth=getEpicDataList(data, keyGeoDepth, records)\nlistGeoType=getEpicDataList(data, keyGeoType, records)\n\nlistPropAlert=getEpicDataList(data, keyPropAlert, records)\nlistPropCdi=getEpicDataList(data, keyPropCdi, records)\nlistPropCode=getEpicDataList(data, keyPropCode, records)\nlistPropDetail=getEpicDataList(data, keyPropDetail, records)\nlistPropDmin=getEpicDataList(data, keyPropDmin, records)\nlistPropFelt=getEpicDataList(data, keyPropFelt, records)\nlistPropGap=getEpicDataList(data, keyPropGap, records)\nlistPropIds=getEpicDataList(data, keyPropIds, records)\nlistPropMag=getEpicDataList(data, keyPropMag, records)\nlistPropMagType=getEpicDataList(data, keyPropMagType, records)\nlistPropMmi=getEpicDataList(data, keyPropMmi, records)\nlistPropNet=getEpicDataList(data, keyPropNet, records)\nlistPropNst=getEpicDataList(data, keyPropNst, records)\nlistPropPlace=getEpicDataList(data, keyPropPlace, records)\nlistPropRms=getEpicDataList(data, keyPropRms, records)\nlistPropSig=getEpicDataList(data, keyPropSig, records)\nlistPropSources=getEpicDataList(data, keyPropSources, records)\nlistPropStatus=getEpicDataList(data, keyPropStatus, records)\nlistPropTime=getEpicDataList(data, keyPropTime, records)\nlistPropTitle=getEpicDataList(data, keyPropTitle, records)\nlistPropTsunami=getEpicDataList(data, keyPropTsunami, records)\nlistPropType=getEpicDataList(data, keyPropType, records)\nlistPropTypes=getEpicDataList(data, keyPropTypes, records)\nlistPropTz=getEpicDataList(data, keyPropTz, records)\nlistPropUpdated=getEpicDataList(data, keyPropUpdated, records)\nlistPropUrl=getEpicDataList(data, keyPropUrl, records)\n\n# More datas from the detailed json\n\nlistPropEventTime=[]\nlistPropPlace=[]\nlistNearbyCities=[]\nfor jsonurl in listPropDetail:\n    detail=json.loads(urllib.urlopen(jsonurl).read())\n    listPropEventTime.append(str(detail[unicode(\"properties\")][unicode(\"products\")][unicode(\"origin\")][0][unicode(\"properties\")][unicode(\"eventtime\")]))\n    listPropPlace.append(str(detail[unicode(\"properties\")][unicode(\"place\")]))\n    nearby_json_url=str(detail[unicode(\"properties\")][unicode(\"products\")][unicode(\"nearby-cities\")][0][unicode(\"contents\")][unicode(\"nearby-cities.json\")][unicode(\"url\")])\n    nearby_cities=json.loads(urllib.urlopen(nearby_json_url).read())\n    nr_cities=len(nearby_cities)\n    listNearbyCities.append(str(getEpicDataList(nearby_cities, [\"name\"], nr_cities)))\n    \n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Create a data frame of the relevant variables: Source, Network, Time, Longitude, Latitude, Depth, NST, Place, and Magnitude"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "quakes_df = pd.DataFrame({\"Source\":listPropCode,\"Network\":listPropNet,\"Time\":listPropTime,\"Longitude\":listGeoLongitude,\"Latitude\":listGeoLatitude,\n\"Depth\":listGeoDepth,\"NST\":listPropNst,\"Place\":listPropPlace,\"Magnitude\":listPropMag})\nquakes_df",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Depth</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Magnitude</th>\n      <th>NST</th>\n      <th>Network</th>\n      <th>Place</th>\n      <th>Source</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>   3.9</td>\n      <td> 37.4732</td>\n      <td>-118.9790</td>\n      <td> 1.5</td>\n      <td>NaN</td>\n      <td> nc</td>\n      <td> 19km S of Mammoth Lakes, California</td>\n      <td> 72091676</td>\n      <td> 1382305508200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>   6.4</td>\n      <td> 19.3950</td>\n      <td>-155.2865</td>\n      <td> 2.7</td>\n      <td>NaN</td>\n      <td> hv</td>\n      <td>           6km SW of Volcano, Hawaii</td>\n      <td> 60579886</td>\n      <td> 1382305480200</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>   0.6</td>\n      <td> 19.1987</td>\n      <td>-155.6105</td>\n      <td> 3.5</td>\n      <td>NaN</td>\n      <td> hv</td>\n      <td>            13km W of Pahala, Hawaii</td>\n      <td> 60579891</td>\n      <td> 1382305467400</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>  19.9</td>\n      <td> 33.6807</td>\n      <td>-116.6797</td>\n      <td> 1.0</td>\n      <td> 20</td>\n      <td> ci</td>\n      <td>    7km SSE of Idyllwild, California</td>\n      <td> 11381354</td>\n      <td> 1382305317800</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>   3.4</td>\n      <td> 38.8077</td>\n      <td>-122.8178</td>\n      <td> 0.4</td>\n      <td>NaN</td>\n      <td> nc</td>\n      <td>  6km WNW of The Geysers, California</td>\n      <td> 72091671</td>\n      <td> 1382304302400</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td> 100.0</td>\n      <td> 61.7460</td>\n      <td>-152.0249</td>\n      <td> 2.1</td>\n      <td>NaN</td>\n      <td> ak</td>\n      <td>           104km W of Willow, Alaska</td>\n      <td> 10827316</td>\n      <td> 1382303919000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>   1.5</td>\n      <td> 36.0105</td>\n      <td>-120.5812</td>\n      <td> 0.7</td>\n      <td>NaN</td>\n      <td> nc</td>\n      <td>     24km SW of Coalinga, California</td>\n      <td> 72091666</td>\n      <td> 1382303257700</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "output_type": "pyout",
       "prompt_number": 5,
       "text": "   Depth  Latitude  Longitude  Magnitude  NST Network  \\\n0    3.9   37.4732  -118.9790        1.5  NaN      nc   \n1    6.4   19.3950  -155.2865        2.7  NaN      hv   \n2    0.6   19.1987  -155.6105        3.5  NaN      hv   \n3   19.9   33.6807  -116.6797        1.0   20      ci   \n4    3.4   38.8077  -122.8178        0.4  NaN      nc   \n5  100.0   61.7460  -152.0249        2.1  NaN      ak   \n6    1.5   36.0105  -120.5812        0.7  NaN      nc   \n\n                                 Place    Source           Time  \n0  19km S of Mammoth Lakes, California  72091676  1382305508200  \n1            6km SW of Volcano, Hawaii  60579886  1382305480200  \n2             13km W of Pahala, Hawaii  60579891  1382305467400  \n3     7km SSE of Idyllwild, California  11381354  1382305317800  \n4   6km WNW of The Geysers, California  72091671  1382304302400  \n5            104km W of Willow, Alaska  10827316  1382303919000  \n6      24km SW of Coalinga, California  72091666  1382303257700  "
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Earthquakes are constantly happening and so the data is changing every minute. Let's cache this data we are working with so that we have a copy to work with and we will always have this in case we have no internet connection or the government stops maintaining the feed."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from datetime import datetime\nnow=datetime.now()\nnow=str(now)\nfeed = url.split(\"/\")[len(url.split(\"/\"))-1]\nfeed = feed.split(\".\")[0]\nfilename = feed+\"-\"+now+\".csv\"\nprint filename\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "all_hour-2013-10-20 15:04:41.135561.csv\n"
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "ls shows the files you now have in your home directory. There should be a csv file for the one you just read and parsed."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "ls",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "all_hour-2013-10-20 14:36:15.307874.csv  Recent Earthquakes.ipynb\r\nall_hour-2013-10-20 14:46:56.307924.csv  Recent Earthquakes.py\r\neqs7day-M1-2013-10-19.csv                ttest.csv\r\neqs7day-M1-2013-10-20.csv                Untitled0.ipynb\r\nREADME.md                                Untitled0.py\r\n"
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "If you want to use a cached copy from your home directory, remove the comments (###) and run the following line with your choice of file."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "### pd.read_csv(\"all_hour-2013-10-20 14:36:15.307874.csv\")",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Depth</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Magnitude</th>\n      <th>NST</th>\n      <th>Network</th>\n      <th>Place</th>\n      <th>Source</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td> 0</td>\n      <td>  1.5</td>\n      <td> 36.0105</td>\n      <td>-120.5812</td>\n      <td> 0.7</td>\n      <td>NaN</td>\n      <td> nc</td>\n      <td>        24km SW of Coalinga, California</td>\n      <td> 72091666</td>\n      <td> 1382303257700</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td> 1</td>\n      <td>  9.6</td>\n      <td> 35.6697</td>\n      <td>-118.4677</td>\n      <td> 1.4</td>\n      <td> 11</td>\n      <td> ci</td>\n      <td> 4km SSW of Wofford Heights, California</td>\n      <td> 11381338</td>\n      <td> 1382301360000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td> 2</td>\n      <td> 25.2</td>\n      <td> 62.6783</td>\n      <td>-148.6049</td>\n      <td> 0.0</td>\n      <td>NaN</td>\n      <td> ak</td>\n      <td>           81km SSE of Cantwell, Alaska</td>\n      <td> 10827304</td>\n      <td> 1382300822000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td> 3</td>\n      <td> 49.5</td>\n      <td> 61.6809</td>\n      <td>-151.0288</td>\n      <td> 1.8</td>\n      <td>NaN</td>\n      <td> ak</td>\n      <td>               52km W of Willow, Alaska</td>\n      <td> 10827299</td>\n      <td> 1382300507000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td> 4</td>\n      <td>  5.1</td>\n      <td> 60.0634</td>\n      <td>-140.5906</td>\n      <td> 2.4</td>\n      <td>NaN</td>\n      <td> ak</td>\n      <td>             75km NW of Yakutat, Alaska</td>\n      <td> 10827296</td>\n      <td> 1382300419000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "output_type": "pyout",
       "prompt_number": 8,
       "text": "   Unnamed: 0  Depth  Latitude  Longitude  Magnitude  NST Network  \\\n0           0    1.5   36.0105  -120.5812        0.7  NaN      nc   \n1           1    9.6   35.6697  -118.4677        1.4   11      ci   \n2           2   25.2   62.6783  -148.6049        0.0  NaN      ak   \n3           3   49.5   61.6809  -151.0288        1.8  NaN      ak   \n4           4    5.1   60.0634  -140.5906        2.4  NaN      ak   \n\n                                    Place    Source           Time  \n0         24km SW of Coalinga, California  72091666  1382303257700  \n1  4km SSW of Wofford Heights, California  11381338  1382301360000  \n2            81km SSE of Cantwell, Alaska  10827304  1382300822000  \n3                52km W of Willow, Alaska  10827299  1382300507000  \n4              75km NW of Yakutat, Alaska  10827296  1382300419000  "
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "We can filter out the dirty data using [dropna](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.dropna.html) to drop any rows that contain **NaN**."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clean_data = data.dropna(axis=0, how='any')\nclean_data[0:3]",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'dict' object has no attribute 'dropna'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-9-fd5a00cc8ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'dropna'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "In the code above note that I saved the results of `data.dropna()` into a different variable `clean_data` rather than over-writing the old variable `data`. **Why?** Why not just re-use old variable names? And if we did re-use old variable names what extra danger do we have to keep in mind while using the IPython Notebook?"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Now let's just focus on earthquakes in Alaska (my home state! :)"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "alaska = clean_data[clean_data.Src == 'ak']\nalaska[0:10]",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from mpl_toolkits.basemap import Basemap\n\ndef plot_quakes(quakes):\n    m = Basemap(llcrnrlon=-180,llcrnrlat=50.,\n                urcrnrlon=-120.,urcrnrlat=72,\n                resolution='l',area_thresh=1000.,projection='merc',\n                lat_0=62.9540,lon_0=-149.2697)\n    m.drawcoastlines()\n    m.drawcountries()\n    m.fillcontinents(color='coral',lake_color='blue')\n    m.drawmapboundary(fill_color='aqua')\n    x, y = m(quakes.Lon, quakes.Lat)\n    m.plot(x, y, 'k.')\n    return m\n\nplot_quakes(alaska)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}